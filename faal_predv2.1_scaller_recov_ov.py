import logging
import os
import sys
import subprocess
import random
import zipfile
from collections import Counter
from sklearn.metrics.pairwise import cosine_similarity
from io import BytesIO
import shutil
import time
import argparse 
import numpy as np
import pandas as pd
from Bio import SeqIO, AlignIO
from Bio.Align.Applications import MafftCommandline
import joblib
import plotly.io as pio
import matplotlib.pyplot as plt
from gensim.models import Word2Vec
from imblearn.over_sampling import RandomOverSampler, SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import auc, roc_auc_score, roc_curve, f1_score, average_precision_score
from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split
from sklearn.preprocessing import StandardScaler, label_binarize
from tabulate import tabulate
from sklearn.calibration import CalibratedClassifierCV
from PIL import Image
from matplotlib import ticker
import umap.umap_ as umap  # Import for UMAP
import base64
from plotly.graph_objs import Figure
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

# ============================================
# Definitions of Functions and Classes
# ============================================

# Fixing seeds for reproducibility
SEED = 42
np.random.seed(SEED)
random.seed(SEED)

# Logging Configuration
logging.basicConfig(
    level=logging.INFO,  # Change to DEBUG for more verbosity
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler("logs/app.log"),  # Log to file for persistent records
    ],
)

# ============================================
# Streamlit Configuration and Interface
# ============================================

# Ensure st.set_page_config is the very first Streamlit command
st.set_page_config(
    page_title="FAAL_Pred",
    page_icon="üî¨",  # DNA symbol
    layout="wide",
    initial_sidebar_state="expanded",
)

def are_sequences_aligned(fasta_file):
    """
    Checks if all sequences in a FASTA file have the same length.
    """
    lengths = set()
    for record in SeqIO.parse(fasta_file, "fasta"):
        lengths.add(len(record.seq))
    return len(lengths) == 1  # Returns True if all sequences have the same length

def create_unique_model_directory(base_dir, aggregation_method):
    """
    Creates a unique model directory based on the aggregation method.
    
    Parameters:
    - base_dir (str): The base directory for models.
    - aggregation_method (str): The aggregation method used.

    Returns:
    - model_dir (str): Path to the unique model directory.
    """
    model_dir = os.path.join(base_dir, f"models_{aggregation_method}")
    if not os.path.exists(model_dir):
        os.makedirs(model_dir)
    return model_dir

def realign_sequences_with_mafft(input_path, output_path, threads=8):
    """
    Realigns sequences using MAFFT.
    """
    mafft_command = ['mafft', '--thread', str(threads), '--maxiterate', '1000', '--localpair', input_path]
    try:
        with open(output_path, "w") as outfile:
            subprocess.run(mafft_command, stdout=outfile, stderr=subprocess.PIPE, check=True)
        logging.info(f"Realigned sequences saved in {output_path}")
    except subprocess.CalledProcessError as e:
        logging.error(f"Error running MAFFT: {e.stderr.decode()}")
        sys.exit(1)

from sklearn.cluster import DBSCAN, KMeans

def perform_clustering(data, method="DBSCAN", eps=0.5, min_samples=5, n_clusters=3):
    """
    Performs clustering on the data using DBSCAN or K-Means.

    Parameters:
    - data: np.ndarray with data for clustering.
    - method: "DBSCAN" or "K-Means".
    - eps: Parameter for DBSCAN (epsilon).
    - min_samples: Parameter for DBSCAN.
    - n_clusters: Number of clusters for K-Means.

    Returns:
    - labels: Labels generated by the clustering method.
    """
    if method == "DBSCAN":
        clustering_model = DBSCAN(eps=eps, min_samples=min_samples)
    elif method == "K-Means":
        clustering_model = KMeans(n_clusters=n_clusters, random_state=42)
    else:
        raise ValueError(f"Invalid clustering method: {method}")

    labels = clustering_model.fit_predict(data)
    return labels

def plot_roc_curve_global(y_true, y_pred_proba, title, save_as=None, classes=None):
    """
    Plots ROC curve for binary or multiclass classifications.
    """
    lw = 2  # Line width

    # Check if it's binary or multiclass classification
    unique_classes = np.unique(y_true)
    if len(unique_classes) == 2:  # Binary classification
        fpr, tpr, _ = roc_curve(y_true, y_pred_proba[:, 1])
        roc_auc = auc(fpr, tpr)

        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
    else:  # Multiclass classification
        y_bin = label_binarize(y_true, classes=unique_classes)
        n_classes = y_bin.shape[1]

        fpr = dict()
        tpr = dict()
        roc_auc = dict()

        for i in range(n_classes):
            fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_pred_proba[:, i])
            roc_auc[i] = auc(fpr[i], tpr[i])

        plt.figure()

        colors = plt.cm.viridis(np.linspace(0, 1, n_classes))
        for i, color in zip(range(n_classes), colors):
            class_label = classes[i] if classes is not None else unique_classes[i]
            plt.plot(fpr[i], tpr[i], color=color, lw=lw, label=f'ROC curve of class {class_label} (area = {roc_auc[i]:0.2f})')

    plt.plot([0, 1], [0, 1], 'k--', lw=lw)
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate', color='white')
    plt.ylabel('True Positive Rate', color='white')
    plt.title(title, color='white')
    plt.legend(loc="center left", bbox_to_anchor=(1, 0.5))
    if save_as:
        plt.savefig(save_as, bbox_inches='tight', facecolor='#0B3C5D')  # Match the background color
    plt.close()

def get_class_rankings_global(model, X):
    """
    Gets class rankings based on the probabilities predicted by the model.
    """
    if model is None:
        raise ValueError("Model not fitted yet. Please fit the model first.")

    # Obtaining probabilities for each class
    y_pred_proba = model.predict_proba(X)

    # Ranking classes based on probabilities
    class_rankings = []
    for probabilities in y_pred_proba:
        ranked_classes = sorted(zip(model.classes_, probabilities), key=lambda x: x[1], reverse=True)
        formatted_rankings = [f"{cls}: {prob*100:.2f}%" for cls, prob in ranked_classes]
        class_rankings.append(formatted_rankings)

    return class_rankings

def calculate_roc_values(model, X_test, y_test):
    """
    Calculates ROC AUC values for each class.
    """
    n_classes = len(np.unique(y_test))
    y_pred_proba = model.predict_proba(X_test)

    fpr = dict()
    tpr = dict()
    roc_auc = dict()

    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_proba[:, i], pos_label=i)
        roc_auc[i] = auc(fpr[i], tpr[i])

        # Logging ROC values
        logging.info(f"For class {i}:")
        logging.info(f"FPR: {fpr[i]}")
        logging.info(f"TPR: {tpr[i]}")
        logging.info(f"ROC AUC: {roc_auc[i]}")
        logging.info("--------------------------")

    roc_df = pd.DataFrame(list(roc_auc.items()), columns=['Class', 'ROC AUC'])
    return roc_df

def visualize_latent_space_with_similarity(X_original, X_synthetic, y_original, y_synthetic, 
                                           protein_ids_original, protein_ids_synthetic, 
                                           var_assoc_original, var_assoc_synthetic, 
                                           output_dir=None):
    """
    Visualiza o espa√ßo latente usando UMAP 3D com medidas de similaridade entre amostras originais e sint√©ticas.
    """
    import plotly.graph_objects as go
    import pandas as pd
    import numpy as np
    import os
    import logging

    # Combina dados para UMAP
    X_combined = np.vstack([X_original, X_synthetic])
    y_combined = np.hstack([y_original, y_synthetic])

    # Aplica UMAP para redu√ß√£o de dimensionalidade
    umap_reducer = umap.UMAP(n_components=3, random_state=42, n_neighbors=15, min_dist=0.1)
    X_transformed = umap_reducer.fit_transform(X_combined)

    # Divide dados transformados
    X_transformed_original = X_transformed[:len(X_original)]
    X_transformed_synthetic = X_transformed[len(X_original):]

    # Calcula similaridades entre sint√©ticas e originais
    similarities = cosine_similarity(X_synthetic, X_original)
    max_similarities = similarities.max(axis=1)  # Similaridade m√°xima para cada sint√©tica
    closest_indices = similarities.argmax(axis=1)  # √çndices das originais mais pr√≥ximas

    # Cria DataFrames para facilitar
    df_original = pd.DataFrame({
        'x': X_transformed_original[:, 0],
        'y': X_transformed_original[:, 1],
        'z': X_transformed_original[:, 2],
        'Protein ID': protein_ids_original,
        'Associated Variable': var_assoc_original,
        'Type': 'Original'
    })

    df_synthetic = pd.DataFrame({
        'x': X_transformed_synthetic[:, 0],
        'y': X_transformed_synthetic[:, 1],
        'z': X_transformed_synthetic[:, 2],
        'Protein ID': protein_ids_synthetic,
        'Associated Variable': var_assoc_synthetic,
        'Similarity': max_similarities,
        'Closest Protein': [protein_ids_original[idx] for idx in closest_indices],
        'Closest Variable': [var_assoc_original[idx] for idx in closest_indices],
        'Type': 'Synthetic'
    })

    # Cria o gr√°fico interativo 3D com Plotly
    fig = go.Figure()

    # Adiciona pontos para as amostras originais
    fig.add_trace(go.Scatter3d(
        x=df_original['x'], 
        y=df_original['y'],
        z=df_original['z'],
        mode='markers',
        marker=dict(size=8, color='blue', opacity=0.7),
        name='Original',
        text=df_original.apply(lambda row: f"Protein ID: {row['Protein ID']}<br>Associated Variable: {row['Associated Variable']}", axis=1),
        hoverinfo='text'
    ))

    # Adiciona pontos para as amostras sint√©ticas
    fig.add_trace(go.Scatter3d(
        x=df_synthetic['x'], 
        y=df_synthetic['y'],
        z=df_synthetic['z'],
        mode='markers',
        marker=dict(size=8, color='red', opacity=0.7),
        name='Synthetic',
        text=df_synthetic.apply(lambda row: f"Protein ID: {row['Protein ID']}<br>Associated Variable: {row['Associated Variable']}<br>Similarity: {row['Similarity']:.4f}<br>Closest Protein: {row['Closest Protein']}<br>Closest Variable: {row['Closest Variable']}", axis=1),
        hoverinfo='text'
    ))

    # Ajusta layout
    fig.update_layout(
        title="Latent Space Visualization with Similarity (UMAP 3D)",
        scene=dict(
            xaxis_title="UMAP Dimension 1",
            yaxis_title="UMAP Dimension 2",
            zaxis_title="UMAP Dimension 3"
        ),
        legend=dict(orientation="h", y=-0.1),
        template="plotly_dark"
    )

    # Salva o gr√°fico, se o diret√≥rio de sa√≠da for fornecido
    if output_dir:
        umap_similarity_path = os.path.join(output_dir, "umap_similarity_3D.html")
        fig.write_html(umap_similarity_path)
        logging.info(f"Gr√°fico UMAP salvo em {umap_similarity_path}")

    return fig

def format_and_sum_probabilities(associated_rankings):
    """
    Formats and sums probabilities for each category, returning only the top category.
    """
    category_sums = {}
    categories = ['C4-C6-C8', 'C6-C8-C10', 'C8-C10-C12', 'C10-C12-C14', 'C12-C14-C16', 'C14-C16-C18']
    pattern_mapping = {
        'C4-C6-C8': ['C4', 'C6', 'C8'],
        'C6-C8-C10': ['C6', 'C8', 'C10'],
        'C8-C10-C12': ['C8', 'C10', 'C12'],
        'C10-C12-C14': ['C10', 'C12', 'C14'],
        'C12-C14-C16': ['C12', 'C14', 'C16'],
        'C14-C16-C18': ['C14', 'C16', 'C18'],
    }

    # Initialize the sums dictionary
    for category in categories:
        category_sums[category] = 0.0

    # Sum probabilities for each category
    for rank in associated_rankings:
        try:
            prob = float(rank.split(": ")[1].replace("%", ""))
        except (IndexError, ValueError):
            logging.error(f"Error processing ranking string: {rank}")
            continue
        for category, patterns in pattern_mapping.items():
            if any(pattern in rank for pattern in patterns):
                category_sums[category] += prob

    if not category_sums:
        return None, None, None  # No valid data

    # Determine the top category based on sum of probabilities
    top_category, top_sum = max(category_sums.items(), key=lambda x: x[1])

    # Find the top two specificities
    sorted_categories = sorted(category_sums.items(), key=lambda x: x[1], reverse=True)
    top_two = sorted_categories[:2] if len(sorted_categories) >=2 else sorted_categories

    # Extract top two categories and their probabilities
    top_two_categories = [f"{cat} ({prob:.2f}%)" for cat, prob in top_two]

    # Find the top probability category
    top_category_with_confidence = f"{top_category} (1)"

    return top_category_with_confidence, top_sum, top_two_categories


class Support:
    """
    Support class for training and evaluating Random Forest models with oversampling techniques.
    """

    def __init__(self, cv=5, seed=SEED, n_jobs=8):
        self.cv = cv
        self.model = None
        self.seed = seed
        self.n_jobs = n_jobs
        self.train_scores = []
        self.test_scores = []
        self.f1_scores = []
        self.pr_auc_scores = []
        self.roc_results = []
        self.train_sizes = np.linspace(.1, 1.0, 5)
        self.standard = StandardScaler()

        self.best_params = {}

        self.init_params = {
            "n_estimators": 500,
            "max_depth": 15,  # Reduced to prevent overfitting
            "min_samples_split": 5,  # Increased to prevent overfitting
            "min_samples_leaf": 2,
            "criterion": "gini",
            "max_features": "sqrt",  # Changed from 'sqrt' to 'log2'
            "class_weight": "balanced_subsample",  # Automatic class balancing
            "max_leaf_nodes": None,  # Adjusted for greater regularization
            "min_impurity_decrease": 0.01,
            "bootstrap": True,
            "ccp_alpha": 0.001,
            "random_state": self.seed  # Added for RandomForest
        }
            

        self.parameters = {
            "n_estimators": [50, 100, 300, 700, 1000],
            "max_depth": [2, 5, 10, 15,20,30],
            "min_samples_split": [2,5,10,20],
            "min_samples_leaf": [1, 2, 4,8],
            "criterion": ["gini", "entropy"],
            "max_features": ["sqrt", "log2"],
            "class_weight": ["balanced", "balanced_subsample", None],
            "max_leaf_nodes": [5, 10, 20, 30, 50, None],
            "min_impurity_decrease": [0.0, 0.01, 0.05],
            "bootstrap": [True, False],
            "ccp_alpha": [0.0, 0.001, 0.01],
        }


    def _oversample_single_sample_classes(self, X, y, protein_ids=None, var_assoc=None):
        """
        Customizes oversampling to ensure all classes have at least 'self.cv + 1' samples.
        Also captures synthetic data information like protein IDs and associated variables.

        Parameters:
        - X: Features array.
        - y: Labels array.
        - protein_ids: List of original protein IDs.
        - var_assoc: List of original associated variables.

        Returns:
        - X_smote: Features after oversampling.
        - y_smote: Labels after oversampling.
        - synthetic_protein_ids: List of protein IDs for synthetic data.
        - synthetic_var_assoc: List of associated variables for synthetic data.
        """
        logging.info("Starting oversampling process...")

        # Contar a distribui√ß√£o inicial das classes
        counter = Counter(y)
        logging.info(f"Initial class distribution: {counter}")

        # Definir a estrat√©gia de oversampling para garantir pelo menos 'self.cv + 1' amostras por classe
        classes_to_oversample = {cls: max(self.cv + 1, count) for cls, count in counter.items()}
        logging.info(f"Target sampling strategy for RandomOverSampler: {classes_to_oversample}")

        try:
            # Aplicar RandomOverSampler
            ros = RandomOverSampler(sampling_strategy=classes_to_oversample, random_state=self.seed)
            X_ros, y_ros = ros.fit_resample(X, y)
            logging.info(f"Class distribution after RandomOverSampler: {Counter(y_ros)}")
        except ValueError as e:
            logging.error(f"Error during RandomOverSampler: {e}")
            sys.exit(1)

        # Capturar dados sint√©ticos do RandomOverSampler
        synthetic_protein_ids = []
        synthetic_var_assoc = []
        if protein_ids and var_assoc:
            for idx in range(len(X), len(X_ros)):
                synthetic_protein_ids.append(f"synthetic_ros_{idx}")
                synthetic_var_assoc.append(var_assoc[idx % len(var_assoc)])

        try:
            # Aplicar SMOTE para equilibrar ainda mais as classes
            smote = SMOTE(random_state=self.seed)
            X_smote, y_smote = smote.fit_resample(X_ros, y_ros)
            logging.info(f"Class distribution after SMOTE: {Counter(y_smote)}")
        except ValueError as e:
            logging.error(f"Error during SMOTE: {e}")
            sys.exit(1)

        # Capturar dados sint√©ticos do SMOTE
        if protein_ids and var_assoc:
            for idx in range(len(X_ros), len(X_smote)):
                synthetic_protein_ids.append(f"synthetic_smote_{idx}")
                synthetic_var_assoc.append(var_assoc[idx % len(var_assoc)])

        # Salvar contagem das classes no arquivo
        with open("oversampling_counts.txt", "a") as f:
            f.write("Class Distribution after Oversampling:\n")
            for cls, count in Counter(y_smote).items():
                f.write(f"{cls}: {count}\n")

        return X_smote, y_smote, synthetic_protein_ids, synthetic_var_assoc


    def fit(self, X, y, protein_ids=None, var_assoc=None, model_name_prefix='model', model_dir=None, min_kmers=None):
        """
        Treina o modelo com oversampling e valida√ß√£o cruzada.
        """
        logging.info(f"Starting fit method for {model_name_prefix}...")

        # Transformar em arrays numpy
        X = np.array(X)
        y = np.array(y)

        # Determinar min_kmers
        if min_kmers is not None:
            logging.info(f"Using provided min_kmers: {min_kmers}")
        else:
            min_kmers = len(X)
            logging.info(f"min_kmers not provided. Defaulting to the size of X: {min_kmers}")

        # Oversampling inicial
        X_smote, y_smote, synthetic_protein_ids, synthetic_var_assoc = self._oversample_single_sample_classes(
            X, y, protein_ids, var_assoc
        )

        # Combinar dados originais e sint√©ticos
        if protein_ids and var_assoc:
            combined_protein_ids = protein_ids + synthetic_protein_ids
            combined_var_assoc = var_assoc + synthetic_var_assoc
        else:
            combined_protein_ids = None
            combined_var_assoc = None

        # Visualiza√ß√£o do espa√ßo latente ap√≥s o oversampling
        if protein_ids and var_assoc:
            save_path = f"umap_similarity_visualization_{model_name_prefix}.html"
            logging.info("Visualizando o espa√ßo latente com medidas de similaridade...")
            fig = visualize_latent_space_with_similarity(
                X_original=X, 
                X_synthetic=X_smote[len(y):],  # Ajuste para y
                y_original=y, 
                y_synthetic=y_smote[len(y):],
                protein_ids_original=protein_ids,
                protein_ids_synthetic=synthetic_protein_ids,
                var_assoc_original=var_assoc,
                var_assoc_synthetic=synthetic_var_assoc,
                output_dir=model_dir
            )
            logging.info("Visualiza√ß√£o UMAP gerada com sucesso.")

        # Cross-validation com StratifiedKFold
        self.train_scores = []
        self.test_scores = []
        self.f1_scores = []
        self.pr_auc_scores = []

        # Verificar se todas as classes t√™m pelo menos self.cv +1 amostras
        class_counts = Counter(y_smote)
        min_class_count = min(class_counts.values())
        adjusted_n_splits = min(self.cv, min_class_count - 1)  # Porque SMOTE precisa n_samples > n_neighbors
        if adjusted_n_splits < self.cv:
            logging.warning(f"Adjusted n_splits from {self.cv} to {adjusted_n_splits} due to class size constraints.")
            skf = StratifiedKFold(n_splits=adjusted_n_splits, random_state=self.seed, shuffle=True)
        else:
            skf = StratifiedKFold(n_splits=self.cv, random_state=self.seed, shuffle=True)

        for fold_number, (train_index, test_index) in enumerate(skf.split(X_smote, y_smote), start=1):
            X_train, X_test = X_smote[train_index], X_smote[test_index]
            y_train, y_test = y_smote[train_index], y_smote[test_index]

            # Verificar a distribui√ß√£o das classes no conjunto de teste
            unique, counts_fold = np.unique(y_test, return_counts=True)
            fold_class_distribution = dict(zip(unique, counts_fold))
            logging.info(f"Fold {fold_number} [{model_name_prefix}]: Test set class distribution: {fold_class_distribution}")

            # Oversampling para treinamento
            X_train_resampled, y_train_resampled, synthetic_protein_ids_train, synthetic_var_assoc_train = self._oversample_single_sample_classes(
                X_train, 
                y_train, 
                protein_ids=protein_ids if protein_ids else None, 
                var_assoc=var_assoc if var_assoc else None
            )

            # Verificar a distribui√ß√£o das classes ap√≥s o oversampling no treinamento
            train_sample_counts = Counter(y_train_resampled)
            logging.info(f"Fold {fold_number} [{model_name_prefix}]: Training set class distribution after oversampling: {train_sample_counts}")

            with open("training_sample_counts_after_oversampling.txt", "a") as f:
                f.write(f"Fold {fold_number} Training Sample Counts after Oversampling for {model_name_prefix}:\n")
                for cls, count in train_sample_counts.items():
                    f.write(f"{cls}: {count}\n")

            # Treinamento do modelo
            self.model = RandomForestClassifier(**self.init_params, n_jobs=self.n_jobs)
            self.model.fit(X_train_resampled, y_train_resampled)

            # Avalia√ß√£o
            train_score = self.model.score(X_train_resampled, y_train_resampled)
            test_score = self.model.score(X_test, y_test)
            y_pred = self.model.predict(X_test)

            # M√©tricas
            f1 = f1_score(y_test, y_pred, average='weighted')
            self.f1_scores.append(f1)
            self.train_scores.append(train_score)
            self.test_scores.append(test_score)

            # Precision-Recall AUC
            if len(np.unique(y_test)) > 1:
                pr_auc = average_precision_score(y_test, self.model.predict_proba(X_test), average='macro')
            else:
                pr_auc = 0.0  # N√£o pode calcular PR AUC para uma √∫nica classe
            self.pr_auc_scores.append(pr_auc)

            logging.info(f"Fold {fold_number} [{model_name_prefix}]: Train Score: {train_score}")
            logging.info(f"Fold {fold_number} [{model_name_prefix}]: Test Score: {test_score}")
            logging.info(f"Fold {fold_number} [{model_name_prefix}]: F1 Score: {f1}")
            logging.info(f"Fold {fold_number} [{model_name_prefix}]: Precision-Recall AUC: {pr_auc}")

            # Calcular ROC AUC
            try:
                if len(np.unique(y_test)) == 2:
                    fpr, tpr, thresholds = roc_curve(y_test, self.model.predict_proba(X_test)[:, 1])
                    roc_auc_score_value = auc(fpr, tpr)
                    self.roc_results.append((fpr, tpr, roc_auc_score_value))
                else:
                    y_test_bin = label_binarize(y_test, classes=self.model.classes_)
                    roc_auc_score_value = roc_auc_score(y_test_bin, self.model.predict_proba(X_test), multi_class='ovo', average='macro')
                    self.roc_results.append(roc_auc_score_value)
            except ValueError:
                logging.warning(f"Unable to calculate ROC AUC for fold {fold_number} [{model_name_prefix}] due to insufficient class representation.")

            # Realizar Grid Search e salvar o melhor modelo
            best_model, best_params = self._perform_grid_search(X_train_resampled, y_train_resampled)
            self.model = best_model
            self.best_params = best_params

            if model_dir:
                best_model_filename = os.path.join(model_dir, f'best_model_{model_name_prefix}.pkl')
                # Garantir que o diret√≥rio exista
                os.makedirs(os.path.dirname(best_model_filename), exist_ok=True)
                joblib.dump(best_model, best_model_filename)
                logging.info(f"Best model saved as {best_model_filename} for {model_name_prefix}")
            else:
                best_model_filename = f'best_model_{model_name_prefix}.pkl'
                joblib.dump(best_model, best_model_filename)
                logging.info(f"Best model saved as {best_model_filename} for {model_name_prefix}")

            if best_params is not None:
                self.best_params = best_params
                logging.info(f"Best parameters for {model_name_prefix}: {self.best_params}")
            else:
                logging.warning(f"No best parameters found from grid search for {model_name_prefix}.")

            # Integrar Calibra√ß√£o de Probabilidades
            calibrator = CalibratedClassifierCV(self.model, method='isotonic', cv=5, n_jobs=self.n_jobs)
            calibrator.fit(X_train_resampled, y_train_resampled)

            self.model = calibrator

            if model_dir:
                calibrated_model_filename = os.path.join(model_dir, f'calibrated_model_{model_name_prefix}.pkl')
            else:
                calibrated_model_filename = f'calibrated_model_{model_name_prefix}.pkl'
            joblib.dump(calibrator, calibrated_model_filename)
            logging.info(f"Calibrated model saved as {calibrated_model_filename} for {model_name_prefix}")

            fold_number += 1

            # Permitir que o Streamlit atualize a UI
            time.sleep(0.1)

        return self.model

    def _perform_grid_search(self, X_train_resampled, y_train_resampled):
        skf = StratifiedKFold(n_splits=self.cv, random_state=self.seed, shuffle=True)
        grid_search = GridSearchCV(
            RandomForestClassifier(random_state=self.seed),
            self.parameters,
            cv=skf,
            n_jobs=self.n_jobs,
            scoring='roc_auc_ovo',
            verbose=1
        )

        grid_search.fit(X_train_resampled, y_train_resampled)
        logging.info(f"Best parameters from grid search: {grid_search.best_params_}")
        return grid_search.best_estimator_, grid_search.best_params_

    def get_best_param(self, param_name, default=None):
        return self.best_params.get(param_name, default)

    def plot_learning_curve(self, output_path):
        plt.figure()
        plt.plot(self.train_scores, label='Training score')
        plt.plot(self.test_scores, label='Cross-validation score')
        plt.plot(self.f1_scores, label='F1 Score')
        plt.plot(self.pr_auc_scores, label='Precision-Recall AUC')
        plt.title("Learning Curve", color='white')
        plt.xlabel("Fold", fontsize=12, fontweight='bold', color='white')
        plt.ylabel("Score", fontsize=12, fontweight='bold', color='white')
        plt.legend(loc="best")
        plt.grid(color='white', linestyle='--', linewidth=0.5)
        plt.savefig(output_path, facecolor='#0B3C5D')  # Match the background color
        plt.close()

    def get_class_rankings(self, X):
        """
        Gets class rankings for the given data.
        """
        if self.model is None:
            raise ValueError("Model not fitted yet. Please fit the model first.")

        # Obtaining probabilities for each class
        y_pred_proba = self.model.predict_proba(X)

        # Ranking classes based on probabilities
        class_rankings = []
        for probabilities in y_pred_proba:
            ranked_classes = sorted(zip(self.model.classes_, probabilities), key=lambda x: x[1], reverse=True)
            formatted_rankings = [f"{cls}: {prob*100:.2f}%" for cls, prob in ranked_classes]
            class_rankings.append(formatted_rankings)

        return class_rankings

    def test_best_RF(self, X, y, scaler_dir='.'):
        """
        Tests the best Random Forest model with the given data.
        """
        # Load the scaler
        scaler_path = os.path.join(scaler_dir, 'scaler.pkl') if scaler_dir else 'scaler.pkl'
        if os.path.exists(scaler_path):
            scaler = joblib.load(scaler_path)
            logging.info(f"Scaler loaded from {scaler_path}")
        else:
            logging.error(f"Scaler not found at {scaler_path}")
            sys.exit(1)

        X_scaled = scaler.transform(X)

        # Apply oversampling to the entire dataset before splitting
        X_resampled, y_resampled, _, _ = self._oversample_single_sample_classes(X_scaled, y)

        # Split into training and testing
        X_train, X_test, y_train, y_test = train_test_split(
            X_resampled, y_resampled, test_size=0.4, random_state=self.seed, stratify=y_resampled
        )

        # Train RandomForestClassifier with the best parameters
        model = RandomForestClassifier(
            n_estimators=self.best_params.get('n_estimators', 100),
            max_depth=self.best_params.get('max_depth', 5),
            min_samples_split=self.best_params.get('min_samples_split', 4),
            min_samples_leaf=self.best_params.get('min_samples_leaf', 2),
            criterion=self.best_params.get('criterion', 'entropy'),
            max_features=self.best_params.get('max_features', 'log2'),
            class_weight=self.best_params.get('class_weight', 'balanced'),
            max_leaf_nodes=self.best_params.get('max_leaf_nodes', 20),
            min_impurity_decrease=self.best_params.get('min_impurity_decrease', 0.01),
            bootstrap=self.best_params.get('bootstrap', True),
            ccp_alpha=self.best_params.get('ccp_alpha', 0.001),
            random_state=self.seed,
            n_jobs=self.n_jobs
        )
        model.fit(X_train, y_train)  # Fit the model on the training data

        # Integrate Calibration into the Test Model
        calibrator = CalibratedClassifierCV(model, method='isotonic', cv=5, n_jobs=self.n_jobs)
        calibrator.fit(X_train, y_train)
        calibrated_model = calibrator

        # Make predictions
        y_pred = calibrated_model.predict_proba(X_test)
        y_pred_adjusted = adjust_predictions_global(y_pred, method='normalize')

        # Calculate the score (e.g., AUC)
        score = self._calculate_score(y_pred_adjusted, y_test)

        # Calculate additional metrics
        y_pred_classes = calibrated_model.predict(X_test)
        f1 = f1_score(y_test, y_pred_classes, average='weighted')
        if len(np.unique(y_test)) > 1:
            pr_auc = average_precision_score(y_test, y_pred_adjusted, average='macro')
        else:
            pr_auc = 0.0  # Cannot calculate PR AUC for a single class

        # Return the score, best parameters, trained model, and test sets
        return score, f1, pr_auc, self.best_params, calibrated_model, X_test, y_test

    def _calculate_score(self, y_pred, y_test):
        """
        Calculates the score (e.g., ROC AUC) based on predictions and actual labels.
        """
        n_classes = len(np.unique(y_test))
        if y_pred.ndim == 1 or n_classes == 2:
            return roc_auc_score(y_test, y_pred)
        elif y_pred.ndim == 2 and n_classes > 2:
            y_test_bin = label_binarize(y_test, classes=np.unique(y_test))
            return roc_auc_score(y_test_bin, y_pred, multi_class='ovo', average='macro')
        else:
            logging.warning(f"Unexpected shape or number of classes: y_pred shape: {y_pred.shape}, number of classes: {n_classes}")
            return 0

    def plot_roc_curve(self, y_true, y_pred_proba, title, save_as=None, classes=None):
        """
        Plots ROC curve for binary or multiclass classifications.
        """
        plot_roc_curve_global(y_true, y_pred_proba, title, save_as, classes)


class ProteinEmbeddingGenerator:
    def __init__(self, sequences_path, table_data=None, aggregation_method='none'):
        aligned_path = sequences_path
        if not are_sequences_aligned(sequences_path):
            realign_sequences_with_mafft(sequences_path, sequences_path.replace(".fasta", "_aligned.fasta"), threads=1)
            aligned_path = sequences_path.replace(".fasta", "_aligned.fasta")
        else:
            logging.info(f"Sequences are already aligned: {sequences_path}")

        self.alignment = AlignIO.read(aligned_path, 'fasta')
        self.table_data = table_data
        self.embeddings = []
        self.models = {}
        self.aggregation_method = aggregation_method  # Aggregation method: 'none' or 'mean'
        self.min_kmers = None  # To store min_kmers

    def generate_embeddings(self, k=3, step_size=1, word2vec_model_path="word2vec_model.bin", model_dir=None, min_kmers=None, save_min_kmers=False):
        """
        Generates embeddings for protein sequences using Word2Vec, standardizing the number of k-mers.
        """
        # Define the full path of the Word2Vec model
        if model_dir:
            word2vec_model_full_path = os.path.join(model_dir, word2vec_model_path)
        else:
            word2vec_model_full_path = word2vec_model_path

        # Check if the Word2Vec model already exists
        if os.path.exists(word2vec_model_full_path):
            logging.info(f"Word2Vec model found at {word2vec_model_full_path}. Loading the model.")
            model = Word2Vec.load(word2vec_model_full_path)
            self.models['global'] = model
        else:
            logging.info("Word2Vec model not found. Training a new model.")
            # Variable Initialization
            kmer_groups = {}
            all_kmers = []
            kmers_counts = []

            # Generate k-mers
            for record in self.alignment:
                sequence = str(record.seq)
                seq_len = len(sequence)
                protein_accession_alignment = record.id.split()[0]

                # If table data is not provided, skip matching
                if self.table_data is not None:
                    matching_rows = self.table_data['Protein.accession'].str.split().str[0] == protein_accession_alignment
                    matching_info = self.table_data[matching_rows]

                    if matching_info.empty:
                        logging.warning(f"No match in data table for {protein_accession_alignment}")
                        continue  # Skip to the next iteration

                    target_variable = matching_info['Target variable'].values[0]
                    associated_variable = matching_info['Associated variable'].values[0]

                else:
                    # If there's no table, use default values or None
                    target_variable = None
                    associated_variable = None

                logging.info(f"Processing {protein_accession_alignment} with sequence length {seq_len}")

                if seq_len < k:
                    logging.warning(f"Sequence too short for {protein_accession_alignment}. Length: {seq_len}")
                    continue

                # Generate k-mers, allowing k-mers with less than k gaps
                kmers = [sequence[i:i + k] for i in range(0, seq_len - k + 1, step_size)]
                kmers = [kmer for kmer in kmers if kmer.count('-') < k]  # Allows k-mers with less than k gaps

                if not kmers:
                    logging.warning(f"No valid k-mer for {protein_accession_alignment}")
                    continue

                all_kmers.append(kmers)  # Adds the list of k-mers as a sentence
                kmers_counts.append(len(kmers))  # Stores the count of k-mers

                embedding_info = {
                    'protein_accession': protein_accession_alignment,
                    'target_variable': target_variable,
                    'associated_variable': associated_variable,
                    'kmers': kmers  # Stores the k-mers for later use
                }
                kmer_groups[protein_accession_alignment] = embedding_info

            # Determine the minimum number of k-mers
            if not kmers_counts:
                logging.error("No k-mers were collected. Check your sequences and k-mer parameters.")
                sys.exit(1)

            if min_kmers is not None:
                self.min_kmers = min_kmers
                logging.info(f"Using provided min_kmers: {self.min_kmers}")
            else:
                self.min_kmers = min(kmers_counts)
                logging.info(f"Minimum number of k-mers in any sequence: {self.min_kmers}")

            # Save min_kmers if required
            if save_min_kmers and model_dir:
                min_kmers_path = os.path.join(model_dir, 'min_kmers.txt')
                with open(min_kmers_path, 'w') as f:
                    f.write(str(self.min_kmers))
                logging.info(f"min_kmers saved at {min_kmers_path}")

            # Train Word2Vec model using all k-mers
            model = Word2Vec(
                sentences=all_kmers,
                vector_size=125,  # change to 100 if necessary
                window=10,
                min_count=1,
                workers=8,
                sg=1,
                hs=1,  # Hierarchical softmax enabled
                negative=0,  # Negative sampling disabled
                epochs=2500,  # Fixed number of epochs for reproducibility
                seed=SEED  # Fixed seed for reproducibility
            )

            # Create directory for the Word2Vec model if necessary
            if model_dir:
                os.makedirs(os.path.dirname(word2vec_model_full_path), exist_ok=True)

            # Save the Word2Vec model
            model.save(word2vec_model_full_path)
            self.models['global'] = model
            logging.info(f"Word2Vec model saved at {word2vec_model_full_path}")

        # Generate standardized embeddings
        kmer_groups = {}
        kmers_counts = []
        all_kmers = []

        for record in self.alignment:
            sequence_id = record.id.split()[0]  # Use consistent sequence IDs
            sequence = str(record.seq)

            # If table data is not provided, skip matching
            if self.table_data is not None:
                matching_rows = self.table_data['Protein.accession'].str.split().str[0] == sequence_id
                matching_info = self.table_data[matching_rows]

                if matching_info.empty:
                    logging.warning(f"No match in data table for {sequence_id}")
                    continue  # Skip to the next iteration

                target_variable = matching_info['Target variable'].values[0]
                associated_variable = matching_info['Associated variable'].values[0]

            else:
                # If there's no table, use default values or None
                target_variable = None
                associated_variable = None

            kmers = [sequence[i:i + k] for i in range(0, len(sequence) - k + 1, step_size)]
            kmers = [kmer for kmer in kmers if kmer.count('-') < k]  # Allows k-mers with less than k gaps

            if not kmers:
                logging.warning(f"No valid k-mer for {sequence_id}")
                continue

            all_kmers.append(kmers)
            kmers_counts.append(len(kmers))

            embedding_info = {
                'protein_accession': sequence_id,
                'target_variable': target_variable,
                'associated_variable': associated_variable,
                'kmers': kmers
            }
            kmer_groups[sequence_id] = embedding_info

        # Determine the minimum number of k-mers
        if not kmers_counts:
            logging.error("No k-mers were collected. Check your sequences and k-mer parameters.")
            sys.exit(1)

        if min_kmers is not None:
            self.min_kmers = min_kmers
            logging.info(f"Using provided min_kmers: {self.min_kmers}")
        else:
            self.min_kmers = min(kmers_counts)
            logging.info(f"Minimum number of k-mers in any sequence: {self.min_kmers}")

        # Generate standardized embeddings
        for record in self.alignment:
            sequence_id = record.id.split()[0]  # Use consistent sequence IDs
            embedding_info = kmer_groups.get(sequence_id, {})
            kmers_for_protein = embedding_info.get('kmers', [])

            if len(kmers_for_protein) == 0:
                if self.aggregation_method == 'none':
                    embedding_concatenated = np.zeros(self.models['global'].vector_size * self.min_kmers)
                else:
                    embedding_concatenated = np.zeros(self.models['global'].vector_size)
                self.embeddings.append({
                    'protein_accession': sequence_id,
                    'embedding': embedding_concatenated,
                    'target_variable': embedding_info.get('target_variable'),
                    'associated_variable': embedding_info.get('associated_variable')
                })
                continue

            # Select the first min_kmers k-mers
            selected_kmers = kmers_for_protein[:self.min_kmers]

            # Pad with zeros if necessary
            if len(selected_kmers) < self.min_kmers:
                padding = [np.zeros(self.models['global'].vector_size)] * (self.min_kmers - len(selected_kmers))
                selected_kmers.extend(padding)

            # Get embeddings of the selected k-mers
            selected_embeddings = [self.models['global'].wv[kmer] if kmer in self.models['global'].wv else np.zeros(self.models['global'].vector_size) for kmer in selected_kmers]

            if self.aggregation_method == 'none':
                # Concatenate embeddings of the selected k-mers
                embedding_concatenated = np.concatenate(selected_embeddings, axis=0)
            elif self.aggregation_method == 'mean':
                # Aggregate embeddings of the selected k-mers by mean
                embedding_concatenated = np.mean(selected_embeddings, axis=0)
            else:
                # If method not recognized, use concatenation as default
                logging.warning(f"Unknown aggregation method '{self.aggregation_method}'. Using concatenation.")
                embedding_concatenated = np.concatenate(selected_embeddings, axis=0)

            self.embeddings.append({
                'protein_accession': sequence_id,
                'embedding': embedding_concatenated,
                'target_variable': embedding_info.get('target_variable'),
                'associated_variable': embedding_info.get('associated_variable')
            })

            logging.debug(f"Protein ID: {sequence_id}, Embedding Shape: {embedding_concatenated.shape}")

        # Adjust StandardScaler with embeddings for training/prediction
        embeddings_array_train = np.array([entry['embedding'] for entry in self.embeddings])

        # Check if all embeddings have the same shape
        embedding_shapes = set(embedding.shape for embedding in [entry['embedding'] for entry in self.embeddings])
        if len(embedding_shapes) != 1:
            logging.error(f"Inconsistent embedding shapes detected: {embedding_shapes}")
            raise ValueError("Embeddings have inconsistent shapes.")
        else:
            logging.info(f"All embeddings have shape: {embedding_shapes.pop()}")

        # Define the full path of the scaler
        scaler_full_path = os.path.join(model_dir, 'scaler.pkl') if model_dir else 'scaler.pkl'

        # Check if the scaler already exists
        if os.path.exists(scaler_full_path):
            logging.info(f"StandardScaler found at {scaler_full_path}. Loading the scaler.")
            scaler = joblib.load(scaler_full_path)
        else:
            logging.info("StandardScaler not found. Training a new scaler.")
            scaler = StandardScaler().fit(embeddings_array_train)
            joblib.dump(scaler, scaler_full_path)
            logging.info(f"StandardScaler saved at {scaler_full_path}")

    def get_embeddings_and_labels(self, label_type='target_variable'):
        """
        Returns embeddings and associated labels (target_variable or associated_variable).
        """
        embeddings = []
        labels = []

        for embedding_info in self.embeddings:
            embeddings.append(embedding_info['embedding'])
            labels.append(embedding_info[label_type])  # Uses the specified label type

        return np.array(embeddings), np.array(labels)

# Adjust perplexity dynamically (not used anymore since t-SNE is removed)
def compute_perplexity(n_samples):
    return max(5, min(50, n_samples // 100))

def plot_dual_umap(train_embeddings, train_labels, train_protein_ids,
                   predict_embeddings, predict_labels, predict_protein_ids, output_dir):
    """
    Plots two UMAP 3D graphs and saves them as HTML files:
    - Graph 1: Training Data.
    - Graph 2: Predictions.
    
    Parameters:
    - train_embeddings (np.ndarray): Training data embeddings.
    - train_labels (list or array): Labels for training data.
    - train_protein_ids (list): Protein IDs for training data.
    - predict_embeddings (np.ndarray): Prediction data embeddings.
    - predict_labels (list or array): Labels for predictions.
    - predict_protein_ids (list): Protein IDs for predictions.
    - output_dir (str): Directory to save the UMAP plots.
    """
    # Dimensionality reduction using UMAP
    umap_train = umap.UMAP(n_components=3, random_state=42, n_neighbors=15, min_dist=0.1)
    umap_train_result = umap_train.fit_transform(train_embeddings)

    umap_predict = umap.UMAP(n_components=3, random_state=42, n_neighbors=15, min_dist=0.1)
    umap_predict_result = umap_predict.fit_transform(predict_embeddings)

    # Create color maps for training data
    unique_train_labels = sorted(list(set(train_labels)))
    color_map_train = px.colors.qualitative.Dark24
    color_dict_train = {label: color_map_train[i % len(color_map_train)] for i, label in enumerate(unique_train_labels)}

    # Create color maps for predictions
    unique_predict_labels = sorted(list(set(predict_labels)))
    color_map_predict = px.colors.qualitative.Light24
    color_dict_predict = {label: color_map_predict[i % len(color_map_predict)] for i, label in enumerate(unique_predict_labels)}

    # Convert labels to colors
    train_colors = [color_dict_train.get(label, 'gray') for label in train_labels]
    predict_colors = [color_dict_predict.get(label, 'gray') for label in predict_labels]

    # Graph 1: Training Data
    fig_train = go.Figure()
    fig_train.add_trace(go.Scatter3d(
        x=umap_train_result[:, 0],
        y=umap_train_result[:, 1],
        z=umap_train_result[:, 2],
        mode='markers',
        marker=dict(
            size=5,
            color=train_colors,
            opacity=0.8
        ),
        # Real protein IDs added to the 'text' field
        text=[f"Protein ID: {protein_id}<br>Label: {label}" for protein_id, label in zip(train_protein_ids, train_labels)],
        hoverinfo='text',
        name='Training Data'
    ))
    fig_train.update_layout(
        title='UMAP 3D: Training Data',
        scene=dict(
            xaxis=dict(title='Component 1'),
            yaxis=dict(title='Component 2'),
            zaxis=dict(title='Component 3')
        )
    )

    # Graph 2: Predictions
    fig_predict = go.Figure()
    fig_predict.add_trace(go.Scatter3d(
        x=umap_predict_result[:, 0],
        y=umap_predict_result[:, 1],
        z=umap_predict_result[:, 2],
        mode='markers',
        marker=dict(
            size=5,
            color=predict_colors,
            opacity=0.8
        ),
        # Protein IDs added to the 'text' field
        text=[f"Protein ID: {protein_id}<br>Label: {label}" for protein_id, label in zip(predict_protein_ids, predict_labels)],
        hoverinfo='text',
        name='Predictions'
    ))
    fig_predict.update_layout(
        title='UMAP 3D: Predictions',
        scene=dict(
            xaxis=dict(title='Component 1'),
            yaxis=dict(title='Component 2'),
            zaxis=dict(title='Component 3')
        )
    )

    # Save graphs as HTML files
    umap_train_html = os.path.join(output_dir, "umap_train_3d.html")
    umap_predict_html = os.path.join(output_dir, "umap_predict_3d.html")
    
    pio.write_html(fig_train, file=umap_train_html, auto_open=False)
    pio.write_html(fig_predict, file=umap_predict_html, auto_open=False)
    
    logging.info(f"UMAP Training Data saved as {umap_train_html}")
    logging.info(f"UMAP Predictions saved as {umap_predict_html}")

    return fig_train, fig_predict

def plot_predictions_scatterplot_custom(results, output_path, top_n=1):
    """
    Generates a scatter plot showing only the top category with the highest sum of probabilities for each protein.
    
    Y-axis: Protein accession ID
    X-axis: Specificities from C4 to C18 (fixed scale)
    Each point represents the corresponding specificity for the protein.
    Only the top 1 prediction category is plotted per protein.
    Points are colored in a single uniform color, styled for scientific publication.
    
    Parameters:
    - results (dict): Dictionary containing predictions and rankings for proteins.
    - output_path (str): Path to save the scatter plot.
    - top_n (int): Number of top categories to plot (default is 1).
    """
    # Prepare data
    protein_specificities = {}
    
    for seq_id, info in results.items():
        associated_rankings = info.get('associated_ranking', [])
        if not associated_rankings:
            logging.warning(f"No associated ranking data for protein {seq_id}. Skipping...")
            continue

        # Utilize the format_and_sum_probabilities function to get the top category
        top_category_with_confidence, top_sum, top_two_categories = format_and_sum_probabilities(associated_rankings)
        if top_category_with_confidence is None:
            logging.warning(f"No valid category data for protein {seq_id}. Skipping...")
            continue

        # Extract the category without the confidence
        category = top_category_with_confidence.split(" (")[0]
        confidence = top_sum  # Sum of probabilities for the top category

        protein_specificities[seq_id] = {
            'top_category': category,
            'confidence': confidence
        }

    if not protein_specificities:
        logging.warning("No data available to plot the scatterplot.")
        return

    # Sort protein IDs for better visualization
    unique_proteins = sorted(protein_specificities.keys())
    protein_order = {protein: idx for idx, protein in enumerate(unique_proteins)}

    # Create figure
    fig, ax = plt.subplots(figsize=(12, max(6, len(unique_proteins) * 0.5)))  # Adjust height based on the number of proteins

    # Fixed scale for x-axis from C4 to C18
    x_values = list(range(4, 19))

    # Plot points for all proteins with their top 1 category
    for protein, data in protein_specificities.items():
        y = protein_order[protein]
        category = data['top_category']
        confidence = data['confidence']

        # Extract specificities from the category string
        specificities = [int(x[1:]) for x in category.split('-') if x.startswith('C')]

        for spec in specificities:
            ax.scatter(
                spec, y,
                color='#1f78b4',  # Uniform color
                edgecolors='black',
                linewidth=0.5,
                s=100,
                label='_nolegend_'  # Avoid duplication in legend
            )

        # Connect points with lines if multiple specificities
        if len(specificities) > 1:
            ax.plot(
                specificities,
                [y] * len(specificities),
                color='#1f78b4',
                linestyle='-',
                linewidth=1.0,
                alpha=0.7
            )

    # Customize the plot for better publication quality
    ax.set_xlabel('Specificity (C4 to C18)', fontsize=14, fontweight='bold', color='white')
    ax.set_ylabel('Proteins', fontsize=14, fontweight='bold', color='white')
    ax.set_title('Scatterplot of New Sequences Predictions (SS Prediction)', fontsize=16, fontweight='bold', pad=20, color='white')

    # Set fixed x-axis scale and formatting
    ax.set_xticks(x_values)
    ax.set_xticklabels([f'C{spec}' for spec in x_values], fontsize=12, color='white')
    ax.set_yticks(range(len(unique_proteins)))
    ax.set_yticklabels(unique_proteins, fontsize=10, color='white')

    # Set grid and remove unnecessary spines for a clean look
    ax.grid(True, axis='x', linestyle='--', alpha=0.5, color='gray')
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_color('white')
    ax.spines['bottom'].set_color('white')

    # Minor ticks on x-axis for improved visibility
    ax.xaxis.set_minor_locator(ticker.AutoMinorLocator())
    ax.grid(which='minor', axis='x', linestyle=':', linewidth=0.5, alpha=0.6)

    # Adjust layout to avoid label cut-off
    plt.tight_layout()

    # Save figure in high quality for publication
    plt.savefig(output_path, facecolor='#0B3C5D', dpi=600, bbox_inches='tight')  # Matching background color
    plt.close()
    logging.info(f"Scatterplot saved at {output_path}")

def adjust_predictions_global(predicted_proba, method='normalize', alpha=1.0):
    """
    Adjusts the predicted probabilities from the model.
    """
    if method == 'normalize':
        # Normalize probabilities so they sum to 1 for each sample
        logging.info("Normalizing predicted probabilities.")
        adjusted_proba = predicted_proba / predicted_proba.sum(axis=1, keepdims=True)

    elif method == 'smoothing':
        # Apply smoothing to probabilities to avoid extreme values
        logging.info(f"Applying smoothing to predicted probabilities with alpha={alpha}.")
        adjusted_proba = (predicted_proba + alpha) / (predicted_proba.sum(axis=1, keepdims=True) + alpha * predicted_proba.shape[1])

    elif method == 'none':
        # Do not apply any adjustment
        logging.info("No adjustment applied to predicted probabilities.")
        adjusted_proba = predicted_proba.copy()

    else:
        logging.warning(f"Unknown adjustment method '{method}'. No adjustment will be applied.")
        adjusted_proba = predicted_proba.copy()

    return adjusted_proba

def main(args):
    model_dir = args.model_dir  # This should be 'results/models'

    """
    Main function coordinating the workflow.
    """
    model_dir = args.model_dir

    # Initialize progress variables
    total_steps = 8  # Adjusted total steps after removing t-SNE
    current_step = 0
    progress_bar = st.progress(0)
    progress_text = st.empty()

    # =============================
    # STEP 1: Model Training
    # =============================

    # Load training data
    train_alignment_path = args.train_fasta
    train_table_data_path = args.train_table

    # Check if training sequences are aligned
    if not are_sequences_aligned(train_alignment_path):
        logging.info("Training sequences are not aligned. Realigning with MAFFT...")
        aligned_train_path = train_alignment_path.replace(".fasta", "_aligned.fasta")
        realign_sequences_with_mafft(train_alignment_path, aligned_train_path, threads=1)  # Fixed threads=1
        train_alignment_path = aligned_train_path
    else:
        logging.info(f"Aligned training file found or sequences already aligned: {train_alignment_path}")

    # Load training table data
    train_table_data = pd.read_csv(train_table_data_path, delimiter="\t")
    logging.info("Training data table loaded successfully.")

    # Update progress
    current_step += 1
    progress = min(current_step / total_steps, 1.0)
    progress_bar.progress(progress)
    progress_text.markdown(f"<span style='color:white'>Progress: {int(progress * 100)}%</span>", unsafe_allow_html=True)
    time.sleep(0.1)

    # Initialize and generate embeddings for training
    protein_embedding_train = ProteinEmbeddingGenerator(
        train_alignment_path, 
        train_table_data, 
        aggregation_method=args.aggregation_method  # Passing the aggregation method ('none' or 'mean')
    )
    protein_embedding_train.generate_embeddings(
        k=args.kmer_size,
        step_size=args.step_size,
        word2vec_model_path=args.word2vec_model,
        model_dir=model_dir,
        save_min_kmers=True  # Save min_kmers after training
    )
    logging.info(f"Number of training embeddings generated: {len(protein_embedding_train.embeddings)}")

    # Save min_kmers to ensure consistency
    min_kmers = protein_embedding_train.min_kmers

    # Obtendo IDs de prote√≠nas e vari√°veis associadas do conjunto de treinamento
    protein_ids_target = [entry['protein_accession'] for entry in protein_embedding_train.embeddings]
    var_assoc_target = [entry['associated_variable'] for entry in protein_embedding_train.embeddings]

    logging.info(f"Protein IDs for target_variable extracted: {len(protein_ids_target)}")
    logging.info(f"Associated variables for target_variable extracted: {len(var_assoc_target)}")

    # Get embeddings and labels for target_variable
    X_target, y_target = protein_embedding_train.get_embeddings_and_labels(label_type='target_variable')
    logging.info(f"X_target shape: {X_target.shape}")
    
    # Cria√ß√£o do scaler para X_target
    scaler_target = StandardScaler().fit(X_target)
    joblib.dump(scaler_target, os.path.join(model_dir, 'scaler_target.pkl'))
    logging.info("Scaler for X_target created and saved.")

    # Escalando os dados de X_target
    X_target_scaled = scaler_target.transform(X_target)    

    # Full paths for target_variable models
    rf_model_target_full_path = os.path.join(model_dir, args.rf_model_target)
    calibrated_model_target_full_path = os.path.join(model_dir, 'calibrated_model_target.pkl')

    # Update progress
    current_step += 1
    progress = min(current_step / total_steps, 1.0)
    progress_bar.progress(progress)
    progress_text.markdown(f"<span style='color:white'>Progress: {int(progress * 100)}%</span>", unsafe_allow_html=True)
    time.sleep(0.1)

    # Check if calibrated model for target_variable already exists
    if os.path.exists(calibrated_model_target_full_path):
        calibrated_model_target = joblib.load(calibrated_model_target_full_path)
        logging.info(f"Calibrated Random Forest model for target_variable loaded from {calibrated_model_target_full_path}")
    else:
        # Model training for target_variable
        support_model_target = Support()
        calibrated_model_target = support_model_target.fit(X_target_scaled, y_target, protein_ids=protein_ids_target, var_assoc=var_assoc_target, model_name_prefix='target', model_dir=model_dir, min_kmers=min_kmers)

        logging.info("Training and calibration for target_variable completed.")

        # Save the calibrated model
        joblib.dump(calibrated_model_target, calibrated_model_target_full_path)
        logging.info(f"Calibrated Random Forest model for target_variable saved at {calibrated_model_target_full_path}")

        # Test the model
        best_score, best_f1, best_pr_auc, best_params, best_model_target, X_test_target, y_test_target = support_model_target.test_best_RF(X_target_scaled, y_target)

        logging.info(f"Best ROC AUC for target_variable: {best_score}")
        logging.info(f"Best F1 Score for target_variable: {best_f1}")
        logging.info(f"Best Precision-Recall AUC for target_variable: {best_pr_auc}")
        logging.info(f"Best Parameters: {best_params}")

        for param, value in best_params.items():
            logging.info(f"{param}: {value}")

        # Get class rankings
        class_rankings = support_model_target.get_class_rankings(X_test_target)

        # Display rankings for the first 5 samples
        logging.info("Top 3 class rankings for the first 5 samples:")
        for i in range(min(5, len(class_rankings))):
            logging.info(f"Sample {i+1}: Class rankings - {class_rankings[i][:3]}")  # Shows top 3 rankings

        # Plot ROC curve
        n_classes_target = len(np.unique(y_test_target))
        if n_classes_target == 2:
            y_pred_proba_target = best_model_target.predict_proba(X_test_target)[:, 1]
        else:
            y_pred_proba_target = best_model_target.predict_proba(X_test_target)
            unique_classes_target = np.unique(y_test_target).astype(str)
        plot_roc_curve_global(y_test_target, y_pred_proba_target, 'ROC Curve for Target Variable', save_as=args.roc_curve_target, classes=unique_classes_target)

        # Converter y_test_target para r√≥tulos inteiros
        unique_labels = sorted(set(y_test_target))
        label_to_int = {label: idx for idx, label in enumerate(unique_labels)}
        y_test_target_int = [label_to_int[label.strip()] for label in y_test_target]

        # Calcular e imprimir valores ROC para target_variable
        roc_df_target = calculate_roc_values(best_model_target, X_test_target, y_test_target_int)
        logging.info("ROC AUC Scores for target_variable:")
        logging.info(roc_df_target)
        roc_df_target.to_csv(args.roc_values_target, index=False)

    # Update progress
    current_step += 1
    progress = min(current_step / total_steps, 1.0)
    progress_bar.progress(progress)
    progress_text.markdown(f"<span style='color:white'>Progress: {int(progress * 100)}%</span>", unsafe_allow_html=True)
    time.sleep(0.1)

    # Repeat the process for associated_variable
    X_associated, y_associated = protein_embedding_train.get_embeddings_and_labels(label_type='associated_variable')
    logging.info(f"X_associated shape: {X_associated.shape}")
    ####################################################################
    # Cria√ß√£o do scaler para X_associated
    scaler_associated = StandardScaler().fit(X_associated)
    joblib.dump(scaler_associated, os.path.join(model_dir, 'scaler_associated.pkl'))
    logging.info("Scaler for X_associated created and saved.")

    # Escalando os dados de X_associated
    X_associated_scaled = scaler_associated.transform(X_associated)

    #################################################################
    # Full paths for associated_variable models
    rf_model_associated_full_path = os.path.join(model_dir, args.rf_model_associated)
    calibrated_model_associated_full_path = os.path.join(model_dir, 'calibrated_model_associated.pkl')

    # Update progress
    current_step += 1
    progress = min(current_step / total_steps, 1.0)
    progress_bar.progress(progress)
    progress_text.markdown(f"<span style='color:white'>Progress: {int(progress * 100)}%</span>", unsafe_allow_html=True)
    time.sleep(0.1)

    # Check if calibrated model for associated_variable already exists
    if os.path.exists(calibrated_model_associated_full_path):
        calibrated_model_associated = joblib.load(calibrated_model_associated_full_path)
        logging.info(f"Calibrated Random Forest model for associated_variable loaded from {calibrated_model_associated_full_path}")
    else:
        # Model training for associated_variable
        support_model_associated = Support()
        calibrated_model_associated = support_model_associated.fit(X_associated_scaled, y_associated, protein_ids=None, var_assoc=None, model_name_prefix='associated', model_dir=model_dir, min_kmers=min_kmers)

        logging.info("Training and calibration for associated_variable completed.")
        
        # Plot learning curve
        logging.info("Plotting Learning Curve for Associated Variable")
        support_model_associated.plot_learning_curve(args.learning_curve_associated)

        # Save the calibrated model
        joblib.dump(calibrated_model_associated, calibrated_model_associated_full_path)
        logging.info(f"Calibrated Random Forest model for associated_variable saved at {calibrated_model_associated_full_path}")

        # Test the model
        best_score_associated, best_f1_associated, best_pr_auc_associated, best_params_associated, best_model_associated, X_test_associated, y_test_associated = support_model_associated.test_best_RF(X_associated_scaled, y_associated)

        logging.info(f"Best ROC AUC for associated_variable in test_best_RF: {best_score_associated}")
        logging.info(f"Best F1 Score for associated_variable in test_best_RF: {best_f1_associated}")
        logging.info(f"Best Precision-Recall AUC for associated_variable in test_best_RF: {best_pr_auc_associated}")
        logging.info(f"Best Parameters found in test_best_RF: {best_params_associated}")
        logging.info(f"Best model Associated in test_best_RF: {best_model_associated}")

        # Get class rankings for associated_variable
        class_rankings_associated = support_model_associated.get_class_rankings(X_test_associated)
        logging.info("Top 3 class rankings for the first 5 samples in associated data:")
        for i in range(min(5, len(class_rankings_associated))):
            logging.info(f"Sample {i+1}: Class rankings - {class_rankings_associated[i][:3]}")  # Shows top 3 rankings

        # Accessing class_weight from the best_params_associated dictionary
        class_weight = best_params_associated.get('class_weight', None)
        # Printing results
        logging.info(f"Class weight used: {class_weight}")

        # Save the trained model for associated_variable
        joblib.dump(best_model_associated, rf_model_associated_full_path)
        logging.info(f"Random Forest model for associated_variable saved at {rf_model_associated_full_path}")

        # Plot ROC curve for associated_variable
        n_classes_associated = len(np.unique(y_test_associated))
        if n_classes_associated == 2:
            y_pred_proba_associated = best_model_associated.predict_proba(X_test_associated)[:, 1]
        else:
            y_pred_proba_associated = best_model_associated.predict_proba(X_test_associated)
            unique_classes_associated = np.unique(y_test_associated).astype(str)
        plot_roc_curve_global(y_test_associated, y_pred_proba_associated, 'ROC Curve for Associated Variable', save_as=args.roc_curve_associated, classes=unique_classes_associated)

    # Update progress
    current_step += 1
    progress = min(current_step / total_steps, 1.0)
    progress_bar.progress(progress)
    progress_text.markdown(f"<span style='color:white'>Progress: {int(progress * 100)}%</span>", unsafe_allow_html=True)
    time.sleep(0.1)

    # =============================
    # STEP 2: Classifying New Sequences
    # =============================

    # Load min_kmers
    min_kmers_path = os.path.join(model_dir, 'min_kmers.txt')
    if os.path.exists(min_kmers_path):
        with open(min_kmers_path, 'r') as f:
            min_kmers_loaded = int(f.read().strip())
        logging.info(f"Loaded min_kmers: {min_kmers_loaded}")
    else:
        logging.error(f"min_kmers file not found at {min_kmers_path}. Ensure training was completed successfully.")
        sys.exit(1)

    # Load data for prediction
    predict_alignment_path = args.predict_fasta

    # Check if sequences for prediction are aligned
    if not are_sequences_aligned(predict_alignment_path):
        logging.info("Sequences for prediction are not aligned. Realigning with MAFFT...")
        aligned_predict_path = predict_alignment_path.replace(".fasta", "_aligned.fasta")
        realign_sequences_with_mafft(predict_alignment_path, aligned_predict_path, threads=1)  # Fixed threads=1
        predict_alignment_path = aligned_predict_path
    else:
        logging.info(f"Aligned file for prediction found or sequences already aligned: {predict_alignment_path}")

    # Update progress
    current_step += 1
    progress = min(current_step / total_steps, 1.0)
    progress_bar.progress(progress)
    progress_text.markdown(f"<span style='color:white'>Progress: {int(progress * 100)}%</span>", unsafe_allow_html=True)
    time.sleep(0.1)

    # Initialize ProteinEmbedding for prediction, no need for the table
    protein_embedding_predict = ProteinEmbeddingGenerator(
        predict_alignment_path, 
        table_data=None,
        aggregation_method=args.aggregation_method  # Passing the aggregation method ('none' or 'mean')
    )
    protein_embedding_predict.generate_embeddings(
        k=args.kmer_size,
        step_size=args.step_size,
        word2vec_model_path=args.word2vec_model,
        model_dir=model_dir,
        min_kmers=min_kmers_loaded  # Use the same min_kmers as training
    )
    logging.info(f"Number of embeddings for prediction generated: {len(protein_embedding_predict.embeddings)}")

    # Get embeddings for prediction
    X_predict = np.array([entry['embedding'] for entry in protein_embedding_predict.embeddings])

    # Load scalers for target_variable and associated_variable
    scaler_target_path = os.path.join(model_dir, 'scaler_target.pkl')
    scaler_associated_path = os.path.join(model_dir, 'scaler_associated.pkl')

    if os.path.exists(scaler_target_path) and os.path.exists(scaler_associated_path):
        scaler_target = joblib.load(scaler_target_path)
        scaler_associated = joblib.load(scaler_associated_path)
        logging.info("Scalers for target and associated variables loaded successfully.")
    else:
        logging.error("Scalers not found. Ensure training was completed successfully.")
        sys.exit(1)

    # Scale embeddings for prediction using both scalers
    X_predict_scaled_target = scaler_target.transform(X_predict)
    X_predict_scaled_associated = scaler_associated.transform(X_predict)

    # Update progress
    current_step += 1
    progress = min(current_step / total_steps, 1.0)
    progress_bar.progress(progress)
    progress_text.markdown(f"<span style='color:white'>Progress: {int(progress * 100)}%</span>", unsafe_allow_html=True)
    time.sleep(0.1)

    # Perform prediction for target_variable
    predictions_target = calibrated_model_target.predict(X_predict_scaled_target)

    # Perform prediction for associated_variable
    predictions_associated = calibrated_model_associated.predict(X_predict_scaled_associated)

    # Get class rankings
    rankings_target = get_class_rankings_global(calibrated_model_target, X_predict_scaled_target)
    rankings_associated = get_class_rankings_global(calibrated_model_associated, X_predict_scaled_associated)

    # Process and save the results
    results = {}
    for entry, pred_target, pred_associated, ranking_target, ranking_associated in zip(
        protein_embedding_predict.embeddings,
        predictions_target,
        predictions_associated,
        rankings_target,
        rankings_associated
    ):
        sequence_id = entry['protein_accession']
        results[sequence_id] = {
            "target_prediction": pred_target,
            "associated_prediction": pred_associated,
            "target_ranking": ranking_target,
            "associated_ranking": ranking_associated
        }

    # Save the results to a file
    with open(args.results_file, 'w') as f:
        f.write("Protein_ID\tTarget_Prediction\tAssociated_Prediction\tTarget_Ranking\tAssociated_Ranking\n")
        for seq_id, result in results.items():
            f.write(f"{seq_id}\t{result['target_prediction']}\t{result['associated_prediction']}\t{'; '.join(result['target_ranking'])}\t{'; '.join(result['associated_ranking'])}\n")
            logging.info(f"{seq_id} - Target Variable: {result['target_prediction']}, Associated Variable: {result['associated_prediction']}, Target Ranking: {'; '.join(result['target_ranking'])}, Associated Ranking: {'; '.join(result['associated_ranking'])}")

    # Generate the Scatterplot of Predictions
    logging.info("Generating scatterplot of new sequences predictions...")
    plot_predictions_scatterplot_custom(results, args.scatterplot_output)
    logging.info(f"Scatterplot saved at {args.scatterplot_output}")

    st.success("Analysis completed successfully!")

    # Display scatterplot
    st.header("Scatterplot of Predictions")
    scatterplot_path = os.path.join(args.output_dir, "scatterplot_predictions.png")
    if os.path.exists(scatterplot_path):
        st.image(scatterplot_path, use_column_width=True)
    else:
        st.error(f"Scatterplot not found at {scatterplot_path}")

    # Formatar os resultados
    formatted_results = []

    for sequence_id, info in results.items():
        associated_rankings = info.get('associated_ranking', [])
        if not associated_rankings:
            logging.warning(f"No associated ranking data for protein {sequence_id}. Skipping...")
            continue

        top_specificity, confidence, top_two_specificities = format_and_sum_probabilities(associated_rankings)
        if top_specificity is None:
            logging.warning(f"No valid formatting for protein {sequence_id}. Skipping...")
            continue
        formatted_results.append([
            sequence_id,
            top_specificity,
            f"{confidence:.2f}%",
            "; ".join(top_two_specificities)
        ])

    # Converter para DataFrame do pandas
    headers = ["Query Name", "SS Prediction Specificity", "Prediction Confidence", "Top 2     Specificities"]
    df_results = pd.DataFrame(formatted_results, columns=headers)

    # Fun√ß√£o para aplicar estilos personalizados
    def highlight_table(df):
        return df.style.set_table_styles([
            {
                'selector': 'th',
                'props': [
                    ('background-color', '#1E3A8A'),  # Dark blue for headers
                    ('color', 'white'),
                    ('border', '1px solid white'),
                    ('font-weight', 'bold'),
                    ('text-align', 'center')
                ]
            },
            {
                'selector': 'td',
                'props': [
                    ('background-color', '#0B3C5D'),  # Navy blue for odd rows
                    ('color', 'white'),
                    ('border', '1px solid white'),
                    ('text-align', 'center'),
                    ('font-family', 'Arial'),
                    ('font-size', '12px'),
                ]
            },
            {
                'selector': 'tr:nth-child(even) td',
                'props': [
                    ('background-color', '#145B9C')  # Slightly lighter blue for even rows
                ]
            },
            {
                'selector': 'tr:hover td',
                'props': [
                    ('background-color', '#0D4F8B')  # Darker blue on hover
                ]
            },
        ])

    # Aplicar estilos ao DataFrame
    styled_df = highlight_table(df_results)

    # Renderizar a tabela estilizada como HTML
    html = styled_df.to_html(index=False, escape=False)

    # Injetar CSS para download buttons e ajustar estilos adicionais
    st.markdown(
        """
        <style>
        /* Estilo para download buttons */
        .stButton > button {
            background-color: #1E3A8A;
            color: white;
            border: none;
            padding: 10px 24px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 14px;
            margin: 4px 2px;
            cursor: pointer;
            border-radius: 4px;
        }
    
        /* Hover effect para buttons */
        .stButton > button:hover {
            background-color: #0B3C5D;
        }
    
        /* Estilo para a tabela */
        table {
            border-collapse: collapse;
            width: 100%;
        }
    
        /* Ajustar scroll para a tabela */
        .dataframe-container {
            overflow-x: auto;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # Exibir a tabela no Streamlit
    st.header("Formatted Results")

    st.markdown(
        f"""
        <div class="dataframe-container">
            {html}
        </div>
        """,
        unsafe_allow_html=True
    )

    # Opcional: Adicionar bot√µes para download da tabela em CSV e Excel
    # Estiliza√ß√£o dos bot√µes j√° est√° coberta pelo CSS acima
        
    # Estiliza√ß√£o personalizada com CSS para os bot√µes
    st.markdown("""
        <style>
        .stDownloadButton > button {
            background-color: #1E3A8A; /* Azul escuro */
            color: white; /* Texto branco */
            border: none;
            padding: 10px 20px;
            text-align: center;
            text-decoration: none;
            font-size: 14px;
            margin: 4px 2px;
            cursor: pointer;
            border-radius: 4px;
        }
        .stDownloadButton > button:hover {
            background-color: #145B9C; /* Azul mais claro no hover */
        }
        </style>
    """, unsafe_allow_html=True)

    # Bot√£o para download em CSV
    st.download_button(
        label="Download Results as CSV",
        data=df_results.to_csv(index=False).encode('utf-8'),
        file_name='results.csv',
        mime='text/csv',
    )
    

    # Bot√£o para download em Excel
    output = BytesIO() 
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_results.to_excel(writer, index=False, sheet_name='Results')
        writer.close()

        processed_data = output.getvalue()

    st.download_button(
        label="Download Results as Excel",
        data=processed_data,
        file_name='results.xlsx',
        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
    )

        # Prepare results.zip file
    zip_buffer = BytesIO()
    with zipfile.ZipFile(zip_buffer, "w") as zip_file:
        for folder_name, subfolders, filenames in os.walk(args.output_dir):
            for filename in filenames:
                file_path = os.path.join(folder_name, filename)
                zip_file.write(file_path, arcname=os.path.relpath(file_path, args.output_dir))
    zip_buffer.seek(0)

        # Provide download link
    st.header("Download All Results")
    st.download_button(
        label="Download All Results as results.zip",
        data=zip_buffer,
        file_name="results.zip",
        mime="application/zip"
    )

    # Save the results to an Excel file
    df = pd.DataFrame(formatted_results, columns=headers)
    df.to_excel(args.excel_output, index=False)
    logging.info(f"Results saved in {args.excel_output}")

    # Save the table in tabulated format
    with open(args.formatted_results_table, 'w') as f:
        f.write(tabulate(formatted_results, headers=headers, tablefmt="grid"))
    logging.info(f"Formatted table saved in {args.formatted_results_table}")

    # Custom CSS for dark navy blue background and white text
st.markdown(
    """
    <style>
    /* Define the main app background and text color */
    .stApp {
        background-color: #0B3C5D;
        color: white;
    }
    /* Define the sidebar background and text color */
    [data-testid="stSidebar"] {
        background-color: #0B3C5D !important;
        color: white !important;
    }
    /* Ensure all elements inside the sidebar have blue background and white text */
    [data-testid="stSidebar"] * {
        background-color: #0B3C5D !important;
        color: white !important;
    }
    /* Customize input elements inside the sidebar */
    [data-testid="stSidebar"] input,
    [data-testid="stSidebar"] select,
    [data-testid="stSidebar"] textarea,
    [data-testid="stSidebar"] button,
    [data-testid="stSidebar"] .stButton,
    [data-testid="stSidebar"] .stFileUploader,
    [data-testid="stSidebar"] .stSelectbox,
    [data-testid="stSidebar"] .stNumberInput,
    [data-testid="stSidebar"] .stTextInput,
    [data-testid="stSidebar"] .stCheckbox,
    [data-testid="stSidebar"] .stRadio,
    [data-testid="stSidebar"] .stSlider {
        background-color: #1E3A8A !important;
        color: white !important;
    }
    /* Customize file uploader drag and drop area */
    [data-testid="stSidebar"] div[data-testid="stFileUploader"] div {
        background-color: #1E3A8A !important;
        color: white !important;
    }
    /* Customize select dropdown options */
    [data-testid="stSidebar"] .stSelectbox [role="listbox"] {
        background-color: #1E3A8A !important;
        color: white !important;
    }
    /* Remove borders and shadows */
    [data-testid="stSidebar"] .stButton > button,
    [data-testid="stSidebar"] .stFileUploader,
    [data-testid="stSidebar"] .stSelectbox,
    [data-testid="stSidebar"] .stNumberInput,
    [data-testid="stSidebar"] .stTextInput,
    [data-testid="stSidebar"] .stCheckbox,
    [data-testid="stSidebar"] .stRadio,
    [data-testid="stSidebar"] .stSlider {
        border: none !important;
        box-shadow: none !important;
    }
    /* Customize checkbox and radio buttons */
    [data-testid="stSidebar"] .stCheckbox input[type="checkbox"] + div:first-of-type,
    [data-testid="stSidebar"] .stRadio input[type="radio"] + div:first-of-type {
        background-color: #1E3A8A !important;
    }
    /* Customize slider track and thumb */
    [data-testid="stSidebar"] .stSlider > div:first-of-type {
        color: white !important;
    }
    [data-testid="stSidebar"] .stSlider .st-bo {
        background-color: #1E3A8A !important;
    }
    /* Ensure headers are white */
    h1, h2, h3, h4, h5, h6 {
        color: white !important;
    }
    /* Ensure alert messages (st.info, st.error, etc.) have white text */
    div[role="alert"] p {
        color: white !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)
from PIL import Image

def get_base64_image(image_path):
    """
    Encodes an image file to a base64 string.
    
    Parameters:
    - image_path (str): Path to the image file.
    
    Returns:
    - base64 string of the image.
    """
    try:
        with open(image_path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode("utf-8")
    except FileNotFoundError:
        logging.error(f"Image not found at {image_path}.")
        return ""

# Path to the image
image_path = "./images/faal.png"
image_base64 = get_base64_image(image_path)

# Using HTML with st.markdown to align title and text
st.markdown(
    f"""
    <div style="text-align: center; font-family: 'Arial', sans-serif; padding: 30px; background: linear-gradient(to bottom, #f9f9f9, #ffffff); border-radius: 15px; border: 2px solid #dddddd; box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.1); position: relative;">
        <p style="color: black; font-size: 1.5em; font-weight: bold; margin: 0;">
            FAALPred: Predicting Fatty Acid Specificities of Fatty Acyl-AMP Ligases (FAALs) Using Integrated Approaches of Neural Networks, Bioinformatics, and Machine Learning
        </p>
        <p style="color: #2c3e50; font-size: 1.2em; font-weight: normal; margin-top: 10px;">
            Anne Liong, Leandro de Mattos Pereira, and Pedro Le√£o
        </p>
        <p style="color: #2c3e50; font-size: 18px; line-height: 1.8;">
            <strong>FAALPred</strong> is a comprehensive bioinformatics tool designed to predict 
            the chain length specificity of fatty acid substrates, ranging from C4 to C18.
        </p>
        <h5 style="color: #2c3e50; font-size: 20px; font-weight: bold; margin-top: 25px;">ABSTRACT</h5>
        <p style="color: #2c3e50; font-size: 18px; line-height: 1.8; text-align: justify;">
            Fatty Acyl-AMP Ligases (FAALs), identified by Zhang et al. (2011), activate fatty acids of varying lengths for natural product biosynthesis. 
            These substrates enable the production of compounds like nocuolin (<em>Nodularia sp.</em>, Martins et al., 2022) 
            and sulfolipid-1 (<em>Mycobacterium tuberculosis</em>, Yan et al., 2023), with applications in cancer and tuberculosis 
            treatment (Kurt et al., 2017; Gilmore et al., 2012). Dr. Pedro Le√£o and His Team Identified Several of These Natural Products in Cyanobacteria (<a href="https://leaolab.wixsite.com/leaolab" target="_blank" style="color: #3498db; text-decoration: none;">visit here</a>), 
            and FAALpred classifies FAALs by their substrate specificity.
        </p>
        <div style="text-align: center; margin-top: 20px;">
            <img src="data:image/png;base64,{image_base64}" alt="FAAL domain" style="width: auto; height: 120px; object-fit: contain;">
            <p style="text-align: center; color: #2c3e50; font-size: 14px; margin-top: 5px;">
                <em>FAAL domain from Synechococcus sp. PCC7002, link: <a href="https://www.rcsb.org/structure/7R7F" target="_blank" style="color: #3498db; text-decoration: none;">https://www.rcsb.org/structure/7R7F</a></em>
            </p>
        </div>
    </div>
    """,
    unsafe_allow_html=True
)

# Sidebar for input parameters
st.sidebar.header("Input Parameters")

# Function to save uploaded files
def save_uploaded_file(uploaded_file, save_path):
    with open(save_path, 'wb') as f:
        f.write(uploaded_file.getbuffer())
    return save_path

# Input options
use_default_train = st.sidebar.checkbox("Use default training data", value=True)
if not use_default_train:
    train_fasta_file = st.sidebar.file_uploader("Upload Training FASTA File", type=["fasta", "fa", "fna"])
    train_table_file = st.sidebar.file_uploader("Upload Training Table File (TSV)", type=["tsv"])
else:
    train_fasta_file = None
    train_table_file = None

predict_fasta_file = st.sidebar.file_uploader("Upload Prediction FASTA File", type=["fasta", "fa", "fna"])

kmer_size = st.sidebar.number_input("K-mer Size", min_value=1, max_value=10, value=3, step=1)
step_size = st.sidebar.number_input("Step Size", min_value=1, max_value=10, value=1, step=1)
aggregation_method = st.sidebar.selectbox(
    "Aggregation Method",
    options=['none', 'mean'],  # Only 'none' and 'mean' are options
    index=0
)

# Optional Word2Vec Parameters
st.sidebar.header("Optional Word2Vec Parameters")
custom_word2vec = st.sidebar.checkbox("Customize Word2Vec Parameters", value=False)
if custom_word2vec:
    window = st.sidebar.number_input(
        "Window size", min_value=5, max_value=20, value=5, step=5
    )
    workers = st.sidebar.number_input(
        "Workers", min_value=1, max_value=112, value=8, step=8
    )
    epochs = st.sidebar.number_input(
        "Epochs", min_value=1, max_value=2500, value=2, step=100
    )
else:
    window = 10  # Default value
    workers = 8  # Default value
    epochs = 2500  # Default value

# Output directory is set based on the aggregation method
model_dir = create_unique_model_directory("results", aggregation_method)
output_dir = model_dir

# Button to start processing
if st.sidebar.button("Run Analysis"):
    # Paths for internal data
    internal_train_fasta = "data/train.fasta"
    internal_train_table = "data/train_table.tsv"
    
    # Handling training data
    if use_default_train:
        train_fasta_path = internal_train_fasta
        train_table_path = internal_train_table
        st.markdown("<span style='color:white'>Using default training data.</span>", unsafe_allow_html=True)
    else:
        if train_fasta_file is not None and train_table_file is not None:
            train_fasta_path = os.path.join(output_dir, "uploaded_train.fasta")
            train_table_path = os.path.join(output_dir, "uploaded_train_table.tsv")
            save_uploaded_file(train_fasta_file, train_fasta_path)
            save_uploaded_file(train_table_file, train_table_path)
            st.markdown("<span style='color:white'>Uploaded training data will be used.</span>", unsafe_allow_html=True)
        else:
            st.error("Please upload both the training FASTA file and the training table TSV file.")
            st.stop()

    # Handling prediction data
    if predict_fasta_file is not None:
        predict_fasta_path = os.path.join(output_dir, "uploaded_predict.fasta")
        save_uploaded_file(predict_fasta_file, predict_fasta_path)
    else:
        st.error("Please upload a prediction FASTA file.")
        st.stop()
        
    # Remaining parameters
    args = argparse.Namespace(
        train_fasta=train_fasta_path,
        train_table=train_table_path,
        predict_fasta=predict_fasta_path,
        kmer_size=kmer_size,
        step_size=step_size,
        aggregation_method=aggregation_method,
        results_file=os.path.join(output_dir, "predictions.tsv"),
        output_dir=output_dir,
        scatterplot_output=os.path.join(output_dir, "scatterplot_predictions.png"),
        excel_output=os.path.join(output_dir, "results.xlsx"),
        formatted_results_table=os.path.join(output_dir, "formatted_results.txt"),
        roc_curve_target=os.path.join(output_dir, "roc_curve_target.png"),
        roc_curve_associated=os.path.join(output_dir, "roc_curve_associated.png"),
        learning_curve_target=os.path.join(output_dir, "learning_curve_target.png"),
        learning_curve_associated=os.path.join(output_dir, "learning_curve_associated.png"),
        roc_values_target=os.path.join(output_dir, "roc_values_target.csv"),
        rf_model_target="rf_model_target.pkl",
        rf_model_associated="rf_model_associated.pkl",
        word2vec_model="word2vec_model.bin",
        scaler="scaler.pkl",
        model_dir=model_dir,
    )

    # Create model directory if it doesn't exist
    if not os.path.exists(args.model_dir):
        os.makedirs(args.model_dir)

    # Run the main analysis function
    st.markdown("<span style='color:white'>Processing data and running analysis...</span>", unsafe_allow_html=True)
    try:
        main(args)

    except Exception as e:
        st.error(f"An error occurred during processing: {e}")
        logging.error(f"An error occurred: {e}")

# Function to load and resize images with DPI adjustment
def load_and_resize_image_with_dpi(image_path, base_width, dpi=300):
    try:
        # Load the image
        image = Image.open(image_path)
        # Calculate the new height proportional to the base width
        w_percent = (base_width / float(image.size[0]))
        h_size = int((float(image.size[1]) * float(w_percent)))
        # Resize the image
        resized_image = image.resize((base_width, h_size), Image.Resampling.LANCZOS)
        return resized_image
    except FileNotFoundError:
        logging.error(f"Image not found at {image_path}.")
        return None

# Function to encode images as base64
def encode_image(image):
    buffer = BytesIO()
    image.save(buffer, format="PNG")
    img_str = base64.b64encode(buffer.getvalue()).decode()
    return img_str

# Definitions of image paths
image_dir = "images"
image_paths = [
    os.path.join(image_dir, "lab_logo.png"),
    os.path.join(image_dir, "ciimar.png"),
    os.path.join(image_dir, "faal_pred_logo.png"), 
    os.path.join(image_dir, "bbf4.png"),
    os.path.join(image_dir, "google.png"),
    os.path.join(image_dir, "uniao.png"),
]

# Load and resize all images
images = [load_and_resize_image_with_dpi(path, base_width=150, dpi=300) for path in image_paths]

# Encode images as base64
encoded_images = [encode_image(img) for img in images if img is not None]

# CSS for footer layout
st.markdown(
    """
    <style>
    .footer-container {
        display: flex;
        justify-content: center;
        align-items: center;
        gap: 10px;
        margin-bottom: 10px;
        flex-wrap: wrap;
    }
    .footer-text {
        text-align: center;
        color: white;
        font-size: 12px;
        margin-top: 10px;
    }
    .support-text {
        text-align: center;
        color: white;
        font-size: 14px;
        font-weight: bold;
        margin-bottom: 5px;
    }
    </style>
    """,
    unsafe_allow_html=True,
)


# HTML for displaying images in footer
footer_html = """
<div class="support-text">Support by:</div>
<div class="footer-container">
    {}
</div>
<div class="footer-text">
    CIIMAR - Pedro Le√£o @CNP - 2024 - Leandro de Mattos Pereira (developer) - All rights reserved.
</div>
"""

# Generate <img> tags for each image
img_tags = "".join(
    f'<img src="data:image/png;base64,{img}" style="width: 100px;">' for img in encoded_images
)

# Render the footer
st.markdown(footer_html.format(img_tags), unsafe_allow_html=True)

# ============================================
# End of Script
# ============================================
